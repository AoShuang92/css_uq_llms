{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762499f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 19:31:10.528215: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-08 19:31:11.501325: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/data/user-data/sa25729/myenv1/lib/python3.8/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing similarities:  60%|█████████████████████████████████████▏                        | 3/5 [00:00<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_embeds torch.Size([84, 512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "all_prob_pairs 42 torch.Size([512]) torch.Size([512])\n",
      "text_embeds torch.Size([128, 512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "all_prob_pairs 64 torch.Size([512]) torch.Size([512])\n",
      "text_embeds torch.Size([128, 512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "all_prob_pairs 64 torch.Size([512]) torch.Size([512])\n",
      "text_embeds torch.Size([56, 512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "all_prob_pairs 28 torch.Size([512]) torch.Size([512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing similarities: 100%|██████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  6.13it/s]\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_embeds torch.Size([128, 512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "all_prob_pairs 64 torch.Size([512]) torch.Size([512])\n",
      "text_embeds torch.Size([128, 512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "all_prob_pairs 64 torch.Size([512]) torch.Size([512])\n",
      "text_embeds torch.Size([8, 512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "all_prob_pairs 4 torch.Size([512]) torch.Size([512])\n",
      "text_embeds torch.Size([12, 512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "prob_per_pair_ torch.Size([512])\n",
      "all_prob_pairs 6 torch.Size([512]) torch.Size([512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/myenv1/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:642: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = self.explained_variance_ / total_var\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_ret torch.Size([20, 20, 32])\n",
      "new_ret torch.Size([20, 20, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_ret torch.Size([20, 20, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_ret torch.Size([20, 20, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_ret torch.Size([20, 20, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "projecting: 100%|██████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 35.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits W tensor([[-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.],\n",
      "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf, -inf, -inf, 100.]], dtype=torch.float64)\n",
      "logits temp tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       dtype=torch.float64)\n",
      "W torch.Size([20, 20])\n",
      "logits W tensor([[       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 6.2787e-02,  6.3664e-02, -2.0981e-02, -6.9919e-02, -1.5600e-02,\n",
      "          3.7415e-02,  8.1911e-03, -6.0085e-03,  2.2246e-02, -8.3644e-03,\n",
      "         -1.2354e-02,  3.1090e-03,  1.2044e-02,  2.6901e-02, -4.0697e-04,\n",
      "          6.0962e-05, -2.9205e-01, -1.8004e-01,  1.7006e-01,  2.2940e-01,\n",
      "          7.2011e-02,  2.2582e-01,  5.0396e-02, -2.6851e-01,  1.1080e-01,\n",
      "         -1.5805e-01, -1.8185e-01, -1.7656e-01,  2.1881e-01,  6.6980e-01,\n",
      "         -5.9347e-02, -2.2744e-01],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 6.2787e-02,  6.3664e-02, -2.0981e-02, -6.9919e-02, -1.5600e-02,\n",
      "          3.7415e-02,  8.1911e-03, -6.0085e-03,  2.2246e-02, -8.3644e-03,\n",
      "         -1.2354e-02,  3.1090e-03,  1.2044e-02,  2.6901e-02, -4.0697e-04,\n",
      "          6.0962e-05,  5.2224e-01, -1.8111e-02,  7.6497e-02,  2.8002e-01,\n",
      "          2.8799e-01, -3.1673e-01, -5.3772e-01, -2.3919e-01, -2.5264e-01,\n",
      "         -1.1303e-01, -7.2146e-02, -3.5763e-02,  9.1055e-02,  5.4439e-02,\n",
      "          3.8065e-02, -2.4533e-02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 6.2777e-02,  5.9884e-02,  2.8528e-02,  9.3985e-02,  1.9572e-02,\n",
      "         -1.6012e-02,  3.5220e-02,  5.9927e-02, -4.4792e-02, -1.4728e-03,\n",
      "          1.0125e-02,  1.1790e-03,  9.5787e-03,  5.1202e-02, -8.9046e-03,\n",
      "          1.5083e-02,  4.3300e-01, -6.3161e-01, -3.8858e-01, -1.3184e-01,\n",
      "         -3.9440e-02,  2.5018e-01,  2.2903e-01, -1.6877e-01, -1.1290e-01,\n",
      "          9.8691e-02, -7.0930e-03,  5.3883e-02, -1.4057e-01,  7.8205e-02,\n",
      "         -1.4349e-01, -2.0865e-02],\n",
      "        [ 6.2777e-02,  5.9884e-02,  2.8528e-02,  9.3985e-02,  1.9572e-02,\n",
      "         -1.6012e-02,  3.5220e-02,  5.9927e-02, -4.4792e-02, -1.4728e-03,\n",
      "          1.0125e-02,  1.1790e-03,  9.5787e-03,  5.1202e-02, -8.9046e-03,\n",
      "          1.5083e-02, -2.2500e-02,  9.1140e-02, -2.5456e-01,  5.6350e-02,\n",
      "          1.6248e-01,  2.7570e-01, -3.4598e-03,  3.0964e-01, -2.6175e-01,\n",
      "         -1.6700e-01, -9.8991e-02,  5.2177e-01,  3.9921e-01,  4.6338e-02,\n",
      "          3.7374e-01, -1.3227e-01],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 6.2787e-02,  6.3664e-02, -2.0981e-02, -6.9919e-02, -1.5600e-02,\n",
      "          3.7415e-02,  8.1911e-03, -6.0085e-03,  2.2246e-02, -8.3644e-03,\n",
      "         -1.2354e-02,  3.1090e-03,  1.2044e-02,  2.6901e-02, -4.0697e-04,\n",
      "          6.0962e-05,  1.3777e-01,  6.9533e-02, -4.2599e-02, -4.8890e-01,\n",
      "          1.3942e-01,  2.3107e-01, -4.9065e-01,  1.2327e-01,  5.0846e-01,\n",
      "          1.2343e-01,  2.0792e-01,  1.1417e-01,  1.2378e-02,  2.3657e-01,\n",
      "         -4.9922e-02, -3.5645e-02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 6.2787e-02,  6.3664e-02, -2.0981e-02, -6.9919e-02, -1.5600e-02,\n",
      "          3.7415e-02,  8.1911e-03, -6.0085e-03,  2.2246e-02, -8.3644e-03,\n",
      "         -1.2354e-02,  3.1090e-03,  1.2044e-02,  2.6901e-02, -4.0697e-04,\n",
      "          6.0962e-05,  2.6152e-02,  2.2997e-02, -4.3231e-02,  1.8122e-03,\n",
      "         -4.0068e-02,  4.2447e-02, -2.6460e-02,  5.6026e-02, -2.7159e-02,\n",
      "          2.0367e-01, -1.5104e-01, -2.3257e-01, -5.0423e-01,  1.7117e-01,\n",
      "          7.5075e-01, -8.1897e-02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 6.2787e-02,  6.3664e-02, -2.0981e-02, -6.9919e-02, -1.5600e-02,\n",
      "          3.7415e-02,  8.1911e-03, -6.0085e-03,  2.2246e-02, -8.3644e-03,\n",
      "         -1.2354e-02,  3.1090e-03,  1.2044e-02,  2.6901e-02, -4.0697e-04,\n",
      "          6.0962e-05, -7.0377e-03,  1.8862e-03, -2.8702e-03, -3.9869e-04,\n",
      "         -8.2027e-03, -3.2607e-03,  1.7936e-02,  5.8643e-03, -6.0618e-03,\n",
      "         -1.0004e-03,  3.5199e-03,  5.9059e-03,  3.2498e-03, -2.0214e-02,\n",
      "         -1.2135e-02,  6.5985e-03],\n",
      "        [ 6.2777e-02,  5.9884e-02,  2.8528e-02,  9.3985e-02,  1.9572e-02,\n",
      "         -1.6012e-02,  3.5220e-02,  5.9927e-02, -4.4792e-02, -1.4728e-03,\n",
      "          1.0125e-02,  1.1790e-03,  9.5787e-03,  5.1202e-02, -8.9046e-03,\n",
      "          1.5083e-02, -1.2074e-02,  1.5896e-02,  1.8916e-02,  2.2204e-03,\n",
      "         -3.6187e-03, -1.5467e-02, -6.6344e-03, -4.1433e-03,  1.1019e-02,\n",
      "          2.0090e-03,  3.1201e-03, -1.6931e-02, -7.6070e-03, -3.6630e-03,\n",
      "         -6.7720e-03,  4.5040e-03]], dtype=torch.float64)\n",
      "logits temp tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0321, 0.0322, 0.0304, 0.0294, 0.0305, 0.0316, 0.0310, 0.0307, 0.0313,\n",
      "         0.0307, 0.0306, 0.0309, 0.0311, 0.0314, 0.0308, 0.0308, 0.0254, 0.0273,\n",
      "         0.0345, 0.0359, 0.0323, 0.0358, 0.0319, 0.0258, 0.0332, 0.0277, 0.0273,\n",
      "         0.0274, 0.0357, 0.0482, 0.0296, 0.0265],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0325, 0.0325, 0.0307, 0.0297, 0.0308, 0.0319, 0.0313, 0.0310, 0.0316,\n",
      "         0.0310, 0.0309, 0.0312, 0.0314, 0.0317, 0.0311, 0.0311, 0.0441, 0.0308,\n",
      "         0.0328, 0.0375, 0.0377, 0.0252, 0.0218, 0.0265, 0.0263, 0.0289, 0.0297,\n",
      "         0.0304, 0.0331, 0.0323, 0.0319, 0.0306],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0325, 0.0325, 0.0318, 0.0332, 0.0316, 0.0309, 0.0320, 0.0325, 0.0303,\n",
      "         0.0312, 0.0314, 0.0312, 0.0314, 0.0323, 0.0310, 0.0315, 0.0417, 0.0205,\n",
      "         0.0241, 0.0286, 0.0304, 0.0369, 0.0364, 0.0279, 0.0290, 0.0333, 0.0311,\n",
      "         0.0324, 0.0284, 0.0329, 0.0284, 0.0308],\n",
      "        [0.0313, 0.0312, 0.0306, 0.0319, 0.0304, 0.0297, 0.0307, 0.0312, 0.0291,\n",
      "         0.0300, 0.0302, 0.0300, 0.0302, 0.0310, 0.0298, 0.0303, 0.0295, 0.0319,\n",
      "         0.0253, 0.0311, 0.0334, 0.0360, 0.0299, 0.0369, 0.0252, 0.0268, 0.0281,\n",
      "         0.0425, 0.0391, 0.0309, 0.0385, 0.0275],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0318, 0.0318, 0.0300, 0.0291, 0.0302, 0.0312, 0.0306, 0.0303, 0.0309,\n",
      "         0.0303, 0.0302, 0.0305, 0.0307, 0.0310, 0.0305, 0.0305, 0.0334, 0.0319,\n",
      "         0.0296, 0.0220, 0.0334, 0.0355, 0.0220, 0.0331, 0.0428, 0.0331, 0.0350,\n",
      "         0.0329, 0.0307, 0.0357, 0.0295, 0.0298],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0322, 0.0322, 0.0304, 0.0294, 0.0305, 0.0316, 0.0310, 0.0307, 0.0313,\n",
      "         0.0307, 0.0306, 0.0309, 0.0311, 0.0314, 0.0308, 0.0308, 0.0314, 0.0313,\n",
      "         0.0300, 0.0309, 0.0300, 0.0317, 0.0303, 0.0320, 0.0303, 0.0353, 0.0279,\n",
      "         0.0264, 0.0220, 0.0346, 0.0509, 0.0292],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0325, 0.0325, 0.0308, 0.0298, 0.0309, 0.0320, 0.0314, 0.0311, 0.0317,\n",
      "         0.0310, 0.0309, 0.0313, 0.0314, 0.0318, 0.0312, 0.0312, 0.0310, 0.0312,\n",
      "         0.0311, 0.0312, 0.0310, 0.0311, 0.0316, 0.0313, 0.0311, 0.0312, 0.0313,\n",
      "         0.0313, 0.0313, 0.0308, 0.0309, 0.0313],\n",
      "        [0.0323, 0.0323, 0.0316, 0.0330, 0.0314, 0.0307, 0.0317, 0.0323, 0.0301,\n",
      "         0.0310, 0.0312, 0.0310, 0.0312, 0.0321, 0.0308, 0.0313, 0.0308, 0.0313,\n",
      "         0.0314, 0.0311, 0.0309, 0.0307, 0.0309, 0.0309, 0.0312, 0.0311, 0.0311,\n",
      "         0.0307, 0.0309, 0.0309, 0.0309, 0.0311]], dtype=torch.float64)\n",
      "W torch.Size([20, 20])\n",
      "logits W tensor([[       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 5.3427e-02,  2.5885e-02,  5.4623e-03,  7.9978e-03,  1.9765e-02,\n",
      "          3.2878e-02, -8.2181e-02, -7.0927e-04, -6.8775e-02, -2.7563e-02,\n",
      "         -1.1789e-03, -7.0247e-03, -1.0642e-03,  1.2090e-02, -2.0066e-02,\n",
      "         -5.1667e-02, -3.4821e-02, -3.1868e-02,  5.2719e-02,  1.6168e-02,\n",
      "         -7.1743e-03, -3.0049e-03,  7.0841e-04,  8.0352e-04,  2.5331e-03,\n",
      "          1.6541e-02,  8.0608e-04, -7.7392e-03, -6.0343e-03, -2.0233e-03,\n",
      "          4.5202e-04, -1.4286e-01],\n",
      "        [ 5.4260e-02, -2.9819e-02,  1.5207e-02,  6.0907e-02,  6.0864e-02,\n",
      "          2.7097e-02,  9.7886e-02, -2.8916e-02, -1.5038e-02, -6.4345e-02,\n",
      "         -6.6057e-04, -4.4182e-02, -5.6314e-03, -4.8701e-03,  2.2849e-02,\n",
      "          2.0282e-02,  2.8475e-02, -1.1391e-02,  1.2243e-01, -2.3997e-01,\n",
      "          4.3732e-02, -8.5345e-03,  6.3561e-02,  6.2764e-03, -1.9341e-02,\n",
      "          1.3016e-03, -1.3422e-03,  9.7654e-04, -1.1308e-02,  3.3001e-02,\n",
      "         -1.1405e-04, -3.9598e-02],\n",
      "        [ 5.5004e-02, -5.8974e-02, -1.1505e-01,  3.8030e-02, -8.7747e-02,\n",
      "          3.4898e-02,  9.7118e-03, -5.6164e-03, -1.5690e-02, -1.3652e-02,\n",
      "         -8.9663e-03,  4.7829e-03, -9.2889e-02,  5.6719e-02, -1.7512e-01,\n",
      "         -1.3116e-01,  3.9150e-01, -5.4972e-02, -1.5480e-02,  3.4489e-02,\n",
      "          3.1700e-02, -1.8145e-02,  5.8658e-03,  5.0632e-03,  6.0372e-03,\n",
      "          1.1572e-02,  2.5351e-03,  1.4833e-02,  4.8574e-04,  7.7372e-04,\n",
      "          3.2294e-04,  8.6874e-07],\n",
      "        [ 5.3794e-02, -1.6899e-02,  3.2355e-02,  4.5922e-02,  7.1861e-02,\n",
      "          2.8656e-04, -2.3767e-02,  4.2733e-02,  4.1428e-02,  1.2235e-01,\n",
      "          2.9620e-02,  8.4948e-03,  7.5406e-03, -2.9796e-02,  2.8441e-02,\n",
      "         -3.2172e-02,  2.8371e-02, -7.8593e-03, -6.9396e-04, -5.4743e-03,\n",
      "         -2.8064e-02, -7.5881e-02,  2.7019e-02, -2.8849e-01,  1.0796e-01,\n",
      "         -3.9103e-02, -3.2040e-03, -1.8337e-02, -3.8440e-02,  4.6191e-02,\n",
      "          1.8739e-03, -1.9482e-07],\n",
      "        [ 5.3771e-02, -3.4917e-02,  6.3442e-02, -2.7278e-02, -3.9397e-02,\n",
      "          1.1672e-02, -3.5587e-02,  2.3896e-02,  8.8676e-02, -4.7917e-02,\n",
      "         -1.7482e-02, -1.5114e-02, -6.3905e-04, -1.2560e-02, -1.0006e-02,\n",
      "          1.2303e-02, -1.3769e-02, -1.4605e-01, -7.9547e-02, -3.7888e-02,\n",
      "         -3.5870e-02,  2.7997e-02,  2.5243e-02,  1.1387e-03, -1.9764e-03,\n",
      "          6.2520e-03, -6.1656e-05, -2.0749e-03,  1.1438e-03,  5.8985e-04,\n",
      "          2.5773e-03, -1.8088e-01],\n",
      "        [ 5.0221e-02,  7.8001e-02, -2.1488e-02, -2.8091e-02, -6.3783e-03,\n",
      "         -1.5029e-02,  2.9902e-02, -2.3448e-03,  2.3415e-02,  1.2159e-02,\n",
      "         -1.7326e-02,  1.0648e-02,  2.4772e-03,  5.7503e-03,  3.1837e-03,\n",
      "          9.3719e-03,  4.1447e-03, -1.1117e-02,  1.4189e-02,  4.9941e-03,\n",
      "          1.0059e-03,  2.6045e-03,  4.5556e-03, -2.6646e-03, -1.0802e-03,\n",
      "          5.0556e-03,  9.7702e-03, -5.4626e-03, -1.3905e-02, -1.3628e-02,\n",
      "         -1.5438e-01, -7.0615e-02],\n",
      "        [ 5.4260e-02, -2.9819e-02,  1.5207e-02,  6.0907e-02,  6.0864e-02,\n",
      "          2.7097e-02,  9.7886e-02, -2.8916e-02, -1.5038e-02, -6.4345e-02,\n",
      "         -6.6057e-04, -4.4182e-02, -5.6314e-03, -4.8701e-03,  2.2849e-02,\n",
      "          2.0282e-02,  2.8475e-02, -1.1391e-02,  1.2243e-01, -2.3997e-01,\n",
      "          4.3732e-02, -8.5345e-03,  6.3561e-02,  6.2764e-03, -1.9341e-02,\n",
      "          1.3016e-03, -1.3422e-03,  9.7654e-04, -1.1308e-02,  3.3001e-02,\n",
      "         -1.1405e-04, -3.9598e-02],\n",
      "        [ 5.3427e-02,  2.5885e-02,  5.4623e-03,  7.9978e-03,  1.9765e-02,\n",
      "          3.2878e-02, -8.2181e-02, -7.0927e-04, -6.8775e-02, -2.7563e-02,\n",
      "         -1.1789e-03, -7.0247e-03, -1.0642e-03,  1.2090e-02, -2.0066e-02,\n",
      "         -5.1667e-02, -3.4821e-02, -3.1868e-02,  5.2719e-02,  1.6168e-02,\n",
      "         -7.1743e-03, -3.0049e-03,  7.0841e-04,  8.0352e-04,  2.5331e-03,\n",
      "          1.6541e-02,  8.0608e-04, -7.7392e-03, -6.0343e-03, -2.0233e-03,\n",
      "          4.5202e-04, -1.4286e-01],\n",
      "        [ 5.0221e-02,  7.8001e-02, -2.1488e-02, -2.8091e-02, -6.3783e-03,\n",
      "         -1.5029e-02,  2.9902e-02, -2.3448e-03,  2.3415e-02,  1.2159e-02,\n",
      "         -1.7326e-02,  1.0648e-02,  2.4772e-03,  5.7503e-03,  3.1837e-03,\n",
      "          9.3719e-03,  4.1447e-03, -1.1117e-02,  1.4189e-02,  4.9941e-03,\n",
      "          1.0059e-03,  2.6045e-03,  4.5556e-03, -2.6646e-03, -1.0802e-03,\n",
      "          5.0556e-03,  9.7702e-03, -5.4626e-03, -1.3905e-02, -1.3628e-02,\n",
      "         -1.5438e-01, -7.0615e-02],\n",
      "        [ 5.4225e-02, -4.7141e-02, -3.3015e-02,  4.0449e-02, -5.2031e-02,\n",
      "         -1.2577e-01, -1.2729e-02, -4.5054e-02, -1.6069e-02, -2.9477e-03,\n",
      "          1.6950e-02,  1.7544e-02,  1.6105e-02, -3.3154e-03, -1.7458e-01,\n",
      "          1.3818e-01, -1.3514e-01, -1.1263e-01, -1.1365e-02,  9.4719e-02,\n",
      "          5.8270e-01,  1.9921e-02,  7.4219e-02, -1.0584e-01,  3.9028e-02,\n",
      "          5.4130e-02, -1.2036e-02,  1.3783e-01, -2.4267e-03, -1.0521e-02,\n",
      "          1.6892e-02, -4.7204e-07],\n",
      "        [ 5.0221e-02,  7.8001e-02, -2.1488e-02, -2.8091e-02, -6.3783e-03,\n",
      "         -1.5029e-02,  2.9902e-02, -2.3448e-03,  2.3415e-02,  1.2159e-02,\n",
      "         -1.7326e-02,  1.0648e-02,  2.4772e-03,  5.7503e-03,  3.1837e-03,\n",
      "          9.3719e-03,  4.1447e-03, -1.1117e-02,  1.4189e-02,  4.9941e-03,\n",
      "          1.0059e-03,  2.6045e-03,  4.5556e-03, -2.6646e-03, -1.0802e-03,\n",
      "          5.0556e-03,  9.7702e-03, -5.4626e-03, -1.3905e-02, -1.3628e-02,\n",
      "         -1.5438e-01, -7.0615e-02],\n",
      "        [ 5.0221e-02,  7.8001e-02, -2.1488e-02, -2.8091e-02, -6.3783e-03,\n",
      "         -1.5029e-02,  2.9902e-02, -2.3448e-03,  2.3415e-02,  1.2159e-02,\n",
      "         -1.7326e-02,  1.0648e-02,  2.4772e-03,  5.7503e-03,  3.1837e-03,\n",
      "          9.3719e-03,  4.1447e-03, -1.1117e-02,  1.4189e-02,  4.9941e-03,\n",
      "          1.0059e-03,  2.6045e-03,  4.5556e-03, -2.6646e-03, -1.0802e-03,\n",
      "          5.0556e-03,  9.7702e-03, -5.4626e-03, -1.3905e-02, -1.3628e-02,\n",
      "         -1.5438e-01, -7.0615e-02],\n",
      "        [ 5.3427e-02,  2.5885e-02,  5.4623e-03,  7.9978e-03,  1.9765e-02,\n",
      "          3.2878e-02, -8.2181e-02, -7.0927e-04, -6.8775e-02, -2.7563e-02,\n",
      "         -1.1789e-03, -7.0247e-03, -1.0642e-03,  1.2090e-02, -2.0066e-02,\n",
      "         -5.1667e-02, -3.4821e-02, -3.1868e-02,  5.2719e-02,  1.6168e-02,\n",
      "         -7.1743e-03, -3.0049e-03,  7.0841e-04,  8.0352e-04,  2.5331e-03,\n",
      "          1.6541e-02,  8.0608e-04, -7.7392e-03, -6.0343e-03, -2.0233e-03,\n",
      "          4.5202e-04, -1.4286e-01],\n",
      "        [ 5.3771e-02, -3.4917e-02,  6.3442e-02, -2.7278e-02, -3.9397e-02,\n",
      "          1.1672e-02, -3.5587e-02,  2.3896e-02,  8.8676e-02, -4.7917e-02,\n",
      "         -1.7482e-02, -1.5114e-02, -6.3905e-04, -1.2560e-02, -1.0006e-02,\n",
      "          1.2303e-02, -1.3769e-02, -1.4605e-01, -7.9547e-02, -3.7888e-02,\n",
      "         -3.5870e-02,  2.7997e-02,  2.5243e-02,  1.1387e-03, -1.9764e-03,\n",
      "          6.2520e-03, -6.1656e-05, -2.0749e-03,  1.1438e-03,  5.8985e-04,\n",
      "          2.5773e-03, -1.8088e-01],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 5.3794e-02, -1.6899e-02,  3.2355e-02,  4.5922e-02,  7.1861e-02,\n",
      "          2.8656e-04, -2.3767e-02,  4.2733e-02,  4.1428e-02,  1.2235e-01,\n",
      "          2.9620e-02,  8.4948e-03,  7.5406e-03, -2.9796e-02,  2.8441e-02,\n",
      "         -3.2172e-02,  2.8371e-02, -7.8593e-03, -6.9396e-04, -5.4743e-03,\n",
      "         -2.8064e-02, -7.5881e-02,  2.7019e-02, -2.8849e-01,  1.0796e-01,\n",
      "         -3.9103e-02, -3.2040e-03, -1.8337e-02, -3.8440e-02,  4.6191e-02,\n",
      "          1.8739e-03, -1.9482e-07],\n",
      "        [ 5.3427e-02,  2.5885e-02,  5.4623e-03,  7.9978e-03,  1.9765e-02,\n",
      "          3.2878e-02, -8.2181e-02, -7.0927e-04, -6.8775e-02, -2.7563e-02,\n",
      "         -1.1789e-03, -7.0247e-03, -1.0642e-03,  1.2090e-02, -2.0066e-02,\n",
      "         -5.1667e-02, -3.4821e-02, -3.1868e-02,  5.2719e-02,  1.6168e-02,\n",
      "         -7.1743e-03, -3.0049e-03,  7.0841e-04,  8.0352e-04,  2.5331e-03,\n",
      "          1.6541e-02,  8.0608e-04, -7.7392e-03, -6.0343e-03, -2.0233e-03,\n",
      "          4.5202e-04, -1.4286e-01],\n",
      "        [ 5.3427e-02,  2.5885e-02,  5.4623e-03,  7.9978e-03,  1.9765e-02,\n",
      "          3.2878e-02, -8.2181e-02, -7.0927e-04, -6.8775e-02, -2.7563e-02,\n",
      "         -1.1789e-03, -7.0247e-03, -1.0642e-03,  1.2090e-02, -2.0066e-02,\n",
      "         -5.1667e-02, -3.4821e-02, -3.1868e-02,  5.2719e-02,  1.6168e-02,\n",
      "         -7.1743e-03, -3.0049e-03,  7.0841e-04,  8.0352e-04,  2.5331e-03,\n",
      "          1.6541e-02,  8.0608e-04, -7.7392e-03, -6.0343e-03, -2.0233e-03,\n",
      "          4.5202e-04, -1.4286e-01],\n",
      "        [ 5.0221e-02,  7.8001e-02, -2.1488e-02, -2.8091e-02, -6.3783e-03,\n",
      "         -1.5029e-02,  2.9902e-02, -2.3448e-03,  2.3415e-02,  1.2159e-02,\n",
      "         -1.7326e-02,  1.0648e-02,  2.4772e-03,  5.7503e-03,  3.1837e-03,\n",
      "          9.3719e-03,  4.1447e-03, -1.1117e-02,  1.4189e-02,  4.9941e-03,\n",
      "          1.0059e-03,  2.6045e-03,  4.5556e-03, -2.6646e-03, -1.0802e-03,\n",
      "          5.0556e-03,  9.7702e-03, -5.4626e-03, -1.3905e-02, -1.3628e-02,\n",
      "         -1.5438e-01, -7.0615e-02]], dtype=torch.float64)\n",
      "logits temp tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0325, 0.0319, 0.0315, 0.0316, 0.0318, 0.0321, 0.0297, 0.0314, 0.0300,\n",
      "         0.0308, 0.0314, 0.0313, 0.0314, 0.0317, 0.0310, 0.0303, 0.0307, 0.0307,\n",
      "         0.0325, 0.0317, 0.0313, 0.0313, 0.0314, 0.0314, 0.0315, 0.0318, 0.0314,\n",
      "         0.0312, 0.0313, 0.0314, 0.0314, 0.0285],\n",
      "        [0.0323, 0.0305, 0.0315, 0.0324, 0.0324, 0.0317, 0.0332, 0.0305, 0.0308,\n",
      "         0.0298, 0.0311, 0.0302, 0.0310, 0.0310, 0.0316, 0.0316, 0.0317, 0.0309,\n",
      "         0.0338, 0.0265, 0.0321, 0.0310, 0.0325, 0.0313, 0.0307, 0.0312, 0.0311,\n",
      "         0.0312, 0.0309, 0.0318, 0.0311, 0.0303],\n",
      "        [0.0324, 0.0300, 0.0289, 0.0321, 0.0295, 0.0320, 0.0315, 0.0311, 0.0309,\n",
      "         0.0310, 0.0311, 0.0314, 0.0294, 0.0325, 0.0278, 0.0286, 0.0406, 0.0301,\n",
      "         0.0309, 0.0320, 0.0319, 0.0309, 0.0314, 0.0314, 0.0314, 0.0315, 0.0313,\n",
      "         0.0316, 0.0313, 0.0313, 0.0313, 0.0313],\n",
      "        [0.0323, 0.0308, 0.0318, 0.0321, 0.0327, 0.0312, 0.0307, 0.0321, 0.0320,\n",
      "         0.0338, 0.0318, 0.0313, 0.0313, 0.0305, 0.0318, 0.0305, 0.0318, 0.0310,\n",
      "         0.0311, 0.0310, 0.0306, 0.0296, 0.0317, 0.0257, 0.0335, 0.0304, 0.0311,\n",
      "         0.0308, 0.0304, 0.0321, 0.0312, 0.0312],\n",
      "        [0.0327, 0.0308, 0.0329, 0.0309, 0.0307, 0.0318, 0.0308, 0.0320, 0.0334,\n",
      "         0.0305, 0.0311, 0.0312, 0.0315, 0.0312, 0.0313, 0.0318, 0.0312, 0.0286,\n",
      "         0.0299, 0.0307, 0.0308, 0.0321, 0.0320, 0.0315, 0.0315, 0.0316, 0.0315,\n",
      "         0.0315, 0.0315, 0.0315, 0.0316, 0.0279],\n",
      "        [0.0324, 0.0330, 0.0309, 0.0307, 0.0312, 0.0310, 0.0319, 0.0313, 0.0318,\n",
      "         0.0316, 0.0309, 0.0315, 0.0314, 0.0314, 0.0314, 0.0315, 0.0314, 0.0311,\n",
      "         0.0316, 0.0314, 0.0313, 0.0314, 0.0314, 0.0312, 0.0313, 0.0314, 0.0315,\n",
      "         0.0312, 0.0310, 0.0310, 0.0282, 0.0299],\n",
      "        [0.0323, 0.0305, 0.0315, 0.0324, 0.0324, 0.0317, 0.0332, 0.0305, 0.0308,\n",
      "         0.0298, 0.0311, 0.0302, 0.0310, 0.0310, 0.0316, 0.0316, 0.0317, 0.0309,\n",
      "         0.0338, 0.0265, 0.0321, 0.0310, 0.0325, 0.0313, 0.0307, 0.0312, 0.0311,\n",
      "         0.0312, 0.0309, 0.0318, 0.0311, 0.0303],\n",
      "        [0.0325, 0.0319, 0.0315, 0.0316, 0.0318, 0.0321, 0.0297, 0.0314, 0.0300,\n",
      "         0.0308, 0.0314, 0.0313, 0.0314, 0.0317, 0.0310, 0.0303, 0.0307, 0.0307,\n",
      "         0.0325, 0.0317, 0.0313, 0.0313, 0.0314, 0.0314, 0.0315, 0.0318, 0.0314,\n",
      "         0.0312, 0.0313, 0.0314, 0.0314, 0.0285],\n",
      "        [0.0324, 0.0330, 0.0309, 0.0307, 0.0312, 0.0310, 0.0319, 0.0313, 0.0318,\n",
      "         0.0316, 0.0309, 0.0315, 0.0314, 0.0314, 0.0314, 0.0315, 0.0314, 0.0311,\n",
      "         0.0316, 0.0314, 0.0313, 0.0314, 0.0314, 0.0312, 0.0313, 0.0314, 0.0315,\n",
      "         0.0312, 0.0310, 0.0310, 0.0282, 0.0299],\n",
      "        [0.0320, 0.0299, 0.0302, 0.0317, 0.0298, 0.0284, 0.0306, 0.0300, 0.0305,\n",
      "         0.0308, 0.0312, 0.0312, 0.0312, 0.0308, 0.0275, 0.0339, 0.0282, 0.0286,\n",
      "         0.0306, 0.0329, 0.0455, 0.0313, 0.0324, 0.0288, 0.0317, 0.0320, 0.0306,\n",
      "         0.0338, 0.0308, 0.0307, 0.0312, 0.0309],\n",
      "        [0.0324, 0.0330, 0.0309, 0.0307, 0.0312, 0.0310, 0.0319, 0.0313, 0.0318,\n",
      "         0.0316, 0.0309, 0.0315, 0.0314, 0.0314, 0.0314, 0.0315, 0.0314, 0.0311,\n",
      "         0.0316, 0.0314, 0.0313, 0.0314, 0.0314, 0.0312, 0.0313, 0.0314, 0.0315,\n",
      "         0.0312, 0.0310, 0.0310, 0.0282, 0.0299],\n",
      "        [0.0324, 0.0330, 0.0309, 0.0307, 0.0312, 0.0310, 0.0319, 0.0313, 0.0318,\n",
      "         0.0316, 0.0309, 0.0315, 0.0314, 0.0314, 0.0314, 0.0315, 0.0314, 0.0311,\n",
      "         0.0316, 0.0314, 0.0313, 0.0314, 0.0314, 0.0312, 0.0313, 0.0314, 0.0315,\n",
      "         0.0312, 0.0310, 0.0310, 0.0282, 0.0299],\n",
      "        [0.0325, 0.0319, 0.0315, 0.0316, 0.0318, 0.0321, 0.0297, 0.0314, 0.0300,\n",
      "         0.0308, 0.0314, 0.0313, 0.0314, 0.0317, 0.0310, 0.0303, 0.0307, 0.0307,\n",
      "         0.0325, 0.0317, 0.0313, 0.0313, 0.0314, 0.0314, 0.0315, 0.0318, 0.0314,\n",
      "         0.0312, 0.0313, 0.0314, 0.0314, 0.0285],\n",
      "        [0.0327, 0.0308, 0.0329, 0.0309, 0.0307, 0.0318, 0.0308, 0.0320, 0.0334,\n",
      "         0.0305, 0.0311, 0.0312, 0.0315, 0.0312, 0.0313, 0.0318, 0.0312, 0.0286,\n",
      "         0.0299, 0.0307, 0.0308, 0.0321, 0.0320, 0.0315, 0.0315, 0.0316, 0.0315,\n",
      "         0.0315, 0.0315, 0.0315, 0.0316, 0.0279],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0323, 0.0308, 0.0318, 0.0321, 0.0327, 0.0312, 0.0307, 0.0321, 0.0320,\n",
      "         0.0338, 0.0318, 0.0313, 0.0313, 0.0305, 0.0318, 0.0305, 0.0318, 0.0310,\n",
      "         0.0311, 0.0310, 0.0306, 0.0296, 0.0317, 0.0257, 0.0335, 0.0304, 0.0311,\n",
      "         0.0308, 0.0304, 0.0321, 0.0312, 0.0312],\n",
      "        [0.0325, 0.0319, 0.0315, 0.0316, 0.0318, 0.0321, 0.0297, 0.0314, 0.0300,\n",
      "         0.0308, 0.0314, 0.0313, 0.0314, 0.0317, 0.0310, 0.0303, 0.0307, 0.0307,\n",
      "         0.0325, 0.0317, 0.0313, 0.0313, 0.0314, 0.0314, 0.0315, 0.0318, 0.0314,\n",
      "         0.0312, 0.0313, 0.0314, 0.0314, 0.0285],\n",
      "        [0.0325, 0.0319, 0.0315, 0.0316, 0.0318, 0.0321, 0.0297, 0.0314, 0.0300,\n",
      "         0.0308, 0.0314, 0.0313, 0.0314, 0.0317, 0.0310, 0.0303, 0.0307, 0.0307,\n",
      "         0.0325, 0.0317, 0.0313, 0.0313, 0.0314, 0.0314, 0.0315, 0.0318, 0.0314,\n",
      "         0.0312, 0.0313, 0.0314, 0.0314, 0.0285],\n",
      "        [0.0324, 0.0330, 0.0309, 0.0307, 0.0312, 0.0310, 0.0319, 0.0313, 0.0318,\n",
      "         0.0316, 0.0309, 0.0315, 0.0314, 0.0314, 0.0314, 0.0315, 0.0314, 0.0311,\n",
      "         0.0316, 0.0314, 0.0313, 0.0314, 0.0314, 0.0312, 0.0313, 0.0314, 0.0315,\n",
      "         0.0312, 0.0310, 0.0310, 0.0282, 0.0299]], dtype=torch.float64)\n",
      "W torch.Size([20, 20])\n",
      "logits W tensor([[       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 5.0020e-02, -4.4883e-02,  5.7635e-02,  2.2480e-02, -3.8279e-02,\n",
      "         -1.0774e-02, -3.2664e-02,  7.2409e-03, -2.6307e-02, -2.2797e-02,\n",
      "         -9.9598e-02, -1.5895e-01,  2.0339e-02,  2.1739e-02,  3.5835e-02,\n",
      "         -2.6224e-02, -4.3323e-02,  1.6268e-02,  1.1835e-02, -6.1256e-03,\n",
      "         -5.6302e-04,  3.7032e-03, -4.1913e-04, -4.7682e-08, -7.5945e-09,\n",
      "          3.1046e-10,  5.3259e-08,  4.0488e-02, -2.9081e-01, -3.0684e-01,\n",
      "          2.8363e-01, -6.3423e-02],\n",
      "        [ 4.8842e-02, -1.0071e-01,  8.3977e-02, -5.0235e-02, -4.5979e-02,\n",
      "          5.0259e-02,  2.4119e-02, -1.3761e-02,  2.9878e-02,  2.9530e-02,\n",
      "          3.8915e-02,  4.3309e-02,  1.5605e-02, -6.7716e-03,  1.7309e-03,\n",
      "         -7.6227e-03, -1.4565e-02,  6.2913e-03,  1.5993e-03, -5.4633e-03,\n",
      "         -4.9520e-03, -1.8864e-03,  3.2803e-05, -7.2515e-09,  1.7325e-09,\n",
      "          9.3138e-09, -1.5440e-08, -4.7043e-02, -2.3831e-01, -8.3564e-02,\n",
      "          1.0956e-01,  2.3855e-01],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 4.8842e-02, -1.0071e-01,  8.3977e-02, -5.0235e-02, -4.5979e-02,\n",
      "          5.0259e-02,  2.4119e-02, -1.3761e-02,  2.9878e-02,  2.9530e-02,\n",
      "          3.8915e-02,  4.3309e-02,  1.5605e-02, -6.7716e-03,  1.7309e-03,\n",
      "         -7.6227e-03, -1.4565e-02,  6.2913e-03,  1.5993e-03, -5.4633e-03,\n",
      "         -4.9520e-03, -1.8864e-03,  3.2803e-05, -7.2515e-09,  1.7325e-09,\n",
      "          9.3138e-09, -1.5440e-08,  1.7053e-01,  2.8013e-01,  2.0184e-01,\n",
      "          8.6424e-02, -7.2839e-02],\n",
      "        [ 5.1313e-02,  3.7213e-02,  3.5170e-02,  8.1072e-02, -3.9408e-02,\n",
      "         -2.2262e-02, -5.6217e-02, -9.3209e-03,  1.9798e-02,  1.3642e-02,\n",
      "          1.9951e-02,  3.3749e-02, -4.5409e-03, -3.3215e-04,  3.0253e-02,\n",
      "          2.2941e-02,  9.0143e-03, -4.7910e-03,  1.5009e-03, -1.0876e-03,\n",
      "          4.3188e-04, -4.9799e-03, -1.4793e-05, -6.4772e-09, -6.7354e-09,\n",
      "          2.0276e-09, -8.3806e-10,  4.6638e-01,  1.8193e-01,  5.6171e-01,\n",
      "          1.3407e-01, -2.7356e-04],\n",
      "        [ 4.8842e-02, -1.0071e-01,  8.3977e-02, -5.0235e-02, -4.5979e-02,\n",
      "          5.0259e-02,  2.4119e-02, -1.3761e-02,  2.9878e-02,  2.9530e-02,\n",
      "          3.8915e-02,  4.3309e-02,  1.5605e-02, -6.7716e-03,  1.7309e-03,\n",
      "         -7.6227e-03, -1.4565e-02,  6.2913e-03,  1.5993e-03, -5.4633e-03,\n",
      "         -4.9520e-03, -1.8864e-03,  3.2803e-05, -7.2515e-09,  1.7325e-09,\n",
      "          9.3138e-09, -1.5440e-08, -3.0607e-02, -2.4625e-01,  3.6080e-01,\n",
      "         -5.3655e-02, -2.1892e-01],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 5.1313e-02,  3.7213e-02,  3.5170e-02,  8.1072e-02, -3.9408e-02,\n",
      "         -2.2262e-02, -5.6217e-02, -9.3209e-03,  1.9798e-02,  1.3642e-02,\n",
      "          1.9951e-02,  3.3749e-02, -4.5409e-03, -3.3215e-04,  3.0253e-02,\n",
      "          2.2941e-02,  9.0143e-03, -4.7910e-03,  1.5009e-03, -1.0876e-03,\n",
      "          4.3188e-04, -4.9799e-03, -1.4793e-05, -6.4772e-09, -6.7354e-09,\n",
      "          2.0276e-09, -8.3806e-10, -1.2804e-01,  1.5922e-01,  6.0376e-02,\n",
      "         -2.5142e-01,  1.9800e-01],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 5.1313e-02,  3.7213e-02,  3.5170e-02,  8.1072e-02, -3.9408e-02,\n",
      "         -2.2262e-02, -5.6217e-02, -9.3209e-03,  1.9798e-02,  1.3642e-02,\n",
      "          1.9951e-02,  3.3749e-02, -4.5409e-03, -3.3215e-04,  3.0253e-02,\n",
      "          2.2941e-02,  9.0143e-03, -4.7910e-03,  1.5009e-03, -1.0876e-03,\n",
      "          4.3188e-04, -4.9799e-03, -1.4793e-05, -6.4772e-09, -6.7354e-09,\n",
      "          2.0276e-09, -8.3806e-10,  2.9906e-01,  1.7017e-01, -6.3480e-02,\n",
      "          9.0624e-02,  4.9961e-01],\n",
      "        [ 4.8842e-02, -1.0071e-01,  8.3977e-02, -5.0235e-02, -4.5979e-02,\n",
      "          5.0259e-02,  2.4119e-02, -1.3761e-02,  2.9878e-02,  2.9530e-02,\n",
      "          3.8915e-02,  4.3309e-02,  1.5605e-02, -6.7716e-03,  1.7309e-03,\n",
      "         -7.6227e-03, -1.4565e-02,  6.2913e-03,  1.5993e-03, -5.4633e-03,\n",
      "         -4.9520e-03, -1.8864e-03,  3.2803e-05, -7.2515e-09,  1.7325e-09,\n",
      "          9.3138e-09, -1.5440e-08, -4.2383e-01,  3.4412e-01,  1.1692e-01,\n",
      "          1.0822e-01,  4.1410e-01],\n",
      "        [ 5.1313e-02,  3.7213e-02,  3.5170e-02,  8.1072e-02, -3.9408e-02,\n",
      "         -2.2262e-02, -5.6217e-02, -9.3209e-03,  1.9798e-02,  1.3642e-02,\n",
      "          1.9951e-02,  3.3749e-02, -4.5409e-03, -3.3215e-04,  3.0253e-02,\n",
      "          2.2941e-02,  9.0143e-03, -4.7910e-03,  1.5009e-03, -1.0876e-03,\n",
      "          4.3188e-04, -4.9799e-03, -1.4793e-05, -6.4772e-09, -6.7354e-09,\n",
      "          2.0276e-09, -8.3806e-10, -1.1539e-01, -5.6883e-03,  3.0949e-02,\n",
      "         -2.0134e-01, -2.2259e-02],\n",
      "        [ 5.1313e-02,  3.7213e-02,  3.5170e-02,  8.1072e-02, -3.9408e-02,\n",
      "         -2.2262e-02, -5.6217e-02, -9.3209e-03,  1.9798e-02,  1.3642e-02,\n",
      "          1.9951e-02,  3.3749e-02, -4.5409e-03, -3.3215e-04,  3.0253e-02,\n",
      "          2.2941e-02,  9.0143e-03, -4.7910e-03,  1.5009e-03, -1.0876e-03,\n",
      "          4.3188e-04, -4.9799e-03, -1.4793e-05, -6.4772e-09, -6.7354e-09,\n",
      "          2.0276e-09, -8.3806e-10, -1.6774e-01, -3.5545e-01,  2.2079e-01,\n",
      "         -1.3299e-01,  2.2755e-01],\n",
      "        [ 4.8842e-02, -1.0071e-01,  8.3977e-02, -5.0235e-02, -4.5979e-02,\n",
      "          5.0259e-02,  2.4119e-02, -1.3761e-02,  2.9878e-02,  2.9530e-02,\n",
      "          3.8915e-02,  4.3309e-02,  1.5605e-02, -6.7716e-03,  1.7309e-03,\n",
      "         -7.6227e-03, -1.4565e-02,  6.2913e-03,  1.5993e-03, -5.4633e-03,\n",
      "         -4.9520e-03, -1.8864e-03,  3.2803e-05, -7.2515e-09,  1.7325e-09,\n",
      "          9.3138e-09, -1.5440e-08,  7.0289e-02, -1.1840e-01,  8.5798e-03,\n",
      "          8.0850e-02, -9.3597e-02],\n",
      "        [ 5.1313e-02,  3.7213e-02,  3.5170e-02,  8.1072e-02, -3.9408e-02,\n",
      "         -2.2262e-02, -5.6217e-02, -9.3209e-03,  1.9798e-02,  1.3642e-02,\n",
      "          1.9951e-02,  3.3749e-02, -4.5409e-03, -3.3215e-04,  3.0253e-02,\n",
      "          2.2941e-02,  9.0143e-03, -4.7910e-03,  1.5009e-03, -1.0876e-03,\n",
      "          4.3188e-04, -4.9799e-03, -1.4793e-05, -6.4772e-09, -6.7354e-09,\n",
      "          2.0276e-09, -8.3806e-10, -8.7284e-02,  2.2750e-02, -1.2312e-01,\n",
      "         -5.6109e-02, -9.6120e-02],\n",
      "        [ 5.1313e-02,  3.7213e-02,  3.5170e-02,  8.1072e-02, -3.9408e-02,\n",
      "         -2.2262e-02, -5.6217e-02, -9.3209e-03,  1.9798e-02,  1.3642e-02,\n",
      "          1.9951e-02,  3.3749e-02, -4.5409e-03, -3.3215e-04,  3.0253e-02,\n",
      "          2.2941e-02,  9.0143e-03, -4.7910e-03,  1.5009e-03, -1.0876e-03,\n",
      "          4.3188e-04, -4.9799e-03, -1.4793e-05, -6.4772e-09, -6.7354e-09,\n",
      "          2.0276e-09, -8.3806e-10, -4.0224e-03,  4.4017e-02, -6.7108e-04,\n",
      "         -2.6348e-02, -1.3018e-01],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 5.1313e-02,  3.7213e-02,  3.5170e-02,  8.1072e-02, -3.9408e-02,\n",
      "         -2.2262e-02, -5.6217e-02, -9.3209e-03,  1.9798e-02,  1.3642e-02,\n",
      "          1.9951e-02,  3.3749e-02, -4.5409e-03, -3.3215e-04,  3.0253e-02,\n",
      "          2.2941e-02,  9.0143e-03, -4.7910e-03,  1.5009e-03, -1.0876e-03,\n",
      "          4.3188e-04, -4.9799e-03, -1.4793e-05, -6.4772e-09, -6.7354e-09,\n",
      "          2.0276e-09, -8.3806e-10,  2.7339e-01, -1.7341e-01, -1.2831e-01,\n",
      "          1.1355e-01,  3.8531e-01]], dtype=torch.float64)\n",
      "logits temp tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0326, 0.0306, 0.0328, 0.0321, 0.0308, 0.0314, 0.0309, 0.0317, 0.0310,\n",
      "         0.0311, 0.0295, 0.0284, 0.0320, 0.0320, 0.0323, 0.0310, 0.0307, 0.0319,\n",
      "         0.0318, 0.0314, 0.0316, 0.0317, 0.0316, 0.0316, 0.0316, 0.0316, 0.0316,\n",
      "         0.0324, 0.0260, 0.0257, 0.0381, 0.0303],\n",
      "        [0.0322, 0.0291, 0.0329, 0.0301, 0.0302, 0.0322, 0.0317, 0.0309, 0.0318,\n",
      "         0.0318, 0.0320, 0.0321, 0.0315, 0.0310, 0.0312, 0.0310, 0.0308, 0.0313,\n",
      "         0.0312, 0.0310, 0.0310, 0.0311, 0.0311, 0.0311, 0.0311, 0.0311, 0.0311,\n",
      "         0.0302, 0.0266, 0.0295, 0.0335, 0.0365],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0317, 0.0287, 0.0325, 0.0297, 0.0298, 0.0317, 0.0312, 0.0304, 0.0313,\n",
      "         0.0313, 0.0315, 0.0316, 0.0310, 0.0306, 0.0307, 0.0305, 0.0304, 0.0308,\n",
      "         0.0307, 0.0306, 0.0306, 0.0307, 0.0307, 0.0307, 0.0307, 0.0307, 0.0307,\n",
      "         0.0344, 0.0370, 0.0351, 0.0325, 0.0292],\n",
      "        [0.0312, 0.0309, 0.0308, 0.0318, 0.0294, 0.0297, 0.0290, 0.0299, 0.0305,\n",
      "         0.0304, 0.0305, 0.0308, 0.0300, 0.0301, 0.0307, 0.0306, 0.0303, 0.0300,\n",
      "         0.0302, 0.0301, 0.0301, 0.0300, 0.0301, 0.0301, 0.0301, 0.0301, 0.0301,\n",
      "         0.0411, 0.0340, 0.0438, 0.0329, 0.0301],\n",
      "        [0.0323, 0.0292, 0.0330, 0.0302, 0.0303, 0.0323, 0.0317, 0.0309, 0.0319,\n",
      "         0.0319, 0.0321, 0.0321, 0.0316, 0.0311, 0.0313, 0.0311, 0.0309, 0.0314,\n",
      "         0.0313, 0.0311, 0.0311, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312,\n",
      "         0.0306, 0.0265, 0.0397, 0.0301, 0.0270],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0321, 0.0318, 0.0318, 0.0328, 0.0302, 0.0306, 0.0299, 0.0309, 0.0315,\n",
      "         0.0313, 0.0315, 0.0318, 0.0310, 0.0310, 0.0317, 0.0315, 0.0312, 0.0310,\n",
      "         0.0311, 0.0310, 0.0311, 0.0309, 0.0311, 0.0311, 0.0311, 0.0311, 0.0311,\n",
      "         0.0285, 0.0345, 0.0323, 0.0263, 0.0354],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0314, 0.0312, 0.0311, 0.0321, 0.0296, 0.0299, 0.0293, 0.0302, 0.0308,\n",
      "         0.0307, 0.0308, 0.0311, 0.0303, 0.0304, 0.0310, 0.0309, 0.0306, 0.0303,\n",
      "         0.0304, 0.0304, 0.0304, 0.0303, 0.0304, 0.0304, 0.0304, 0.0304, 0.0304,\n",
      "         0.0371, 0.0340, 0.0291, 0.0323, 0.0424],\n",
      "        [0.0317, 0.0287, 0.0325, 0.0297, 0.0298, 0.0317, 0.0312, 0.0304, 0.0313,\n",
      "         0.0313, 0.0315, 0.0316, 0.0310, 0.0306, 0.0307, 0.0305, 0.0304, 0.0308,\n",
      "         0.0307, 0.0306, 0.0306, 0.0307, 0.0307, 0.0307, 0.0307, 0.0307, 0.0307,\n",
      "         0.0231, 0.0386, 0.0332, 0.0330, 0.0405],\n",
      "        [0.0324, 0.0321, 0.0320, 0.0330, 0.0305, 0.0308, 0.0301, 0.0311, 0.0317,\n",
      "         0.0316, 0.0317, 0.0320, 0.0312, 0.0313, 0.0319, 0.0318, 0.0315, 0.0312,\n",
      "         0.0313, 0.0313, 0.0313, 0.0312, 0.0313, 0.0313, 0.0313, 0.0313, 0.0313,\n",
      "         0.0290, 0.0312, 0.0320, 0.0274, 0.0308],\n",
      "        [0.0323, 0.0320, 0.0319, 0.0329, 0.0304, 0.0307, 0.0300, 0.0310, 0.0316,\n",
      "         0.0315, 0.0316, 0.0319, 0.0311, 0.0312, 0.0318, 0.0317, 0.0314, 0.0311,\n",
      "         0.0312, 0.0312, 0.0312, 0.0311, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312,\n",
      "         0.0279, 0.0246, 0.0361, 0.0285, 0.0363],\n",
      "        [0.0322, 0.0292, 0.0330, 0.0302, 0.0302, 0.0323, 0.0317, 0.0309, 0.0318,\n",
      "         0.0318, 0.0320, 0.0321, 0.0315, 0.0310, 0.0312, 0.0310, 0.0309, 0.0313,\n",
      "         0.0312, 0.0311, 0.0311, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312,\n",
      "         0.0327, 0.0288, 0.0314, 0.0329, 0.0293],\n",
      "        [0.0324, 0.0321, 0.0321, 0.0331, 0.0305, 0.0309, 0.0302, 0.0311, 0.0317,\n",
      "         0.0316, 0.0317, 0.0320, 0.0312, 0.0313, 0.0320, 0.0318, 0.0315, 0.0312,\n",
      "         0.0314, 0.0313, 0.0313, 0.0312, 0.0313, 0.0313, 0.0313, 0.0313, 0.0313,\n",
      "         0.0296, 0.0318, 0.0289, 0.0302, 0.0294],\n",
      "        [0.0323, 0.0320, 0.0319, 0.0329, 0.0304, 0.0307, 0.0300, 0.0310, 0.0316,\n",
      "         0.0315, 0.0316, 0.0319, 0.0311, 0.0312, 0.0318, 0.0317, 0.0314, 0.0311,\n",
      "         0.0312, 0.0312, 0.0312, 0.0311, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312,\n",
      "         0.0311, 0.0321, 0.0312, 0.0306, 0.0286],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0318, 0.0315, 0.0315, 0.0325, 0.0299, 0.0303, 0.0296, 0.0306, 0.0312,\n",
      "         0.0310, 0.0312, 0.0314, 0.0307, 0.0307, 0.0314, 0.0312, 0.0309, 0.0306,\n",
      "         0.0308, 0.0307, 0.0308, 0.0306, 0.0307, 0.0307, 0.0307, 0.0307, 0.0307,\n",
      "         0.0369, 0.0274, 0.0282, 0.0332, 0.0397]], dtype=torch.float64)\n",
      "W torch.Size([20, 20])\n",
      "logits W tensor([[       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 9.7756e-02,  1.1485e-01, -1.2828e-01, -5.2496e-02,  1.1660e-01,\n",
      "         -1.4874e-03,  5.5007e-01,  7.1503e-01,  1.4412e-03, -1.5239e-01,\n",
      "         -3.0784e-01, -1.1230e-01,  3.9173e-15, -3.6832e-16, -1.7522e-16,\n",
      "          1.0254e-16, -8.8157e-17, -1.4696e-16, -2.0026e-17, -1.2400e-17,\n",
      "         -5.6571e-18, -1.1693e-17,  1.4149e-19,  2.5626e-18,  5.8698e-30,\n",
      "          2.5620e-29,  6.1271e-29, -9.5177e-28, -1.9268e-27,  1.6470e-27,\n",
      "         -1.9052e-18,  1.1020e-17],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [ 1.3675e-01, -9.9459e-02, -8.6348e-02,  4.3810e-02, -9.3159e-02,\n",
      "         -9.4390e-02,  9.6751e-17, -1.3561e-17, -2.2729e-17, -5.4941e-17,\n",
      "         -9.1818e-18, -7.4640e-17, -1.5217e-16, -3.5056e-15, -1.2377e-14,\n",
      "         -2.0232e-14,  6.2576e-14,  1.6703e-13,  6.5259e-01,  4.2963e-01,\n",
      "          2.9920e-01,  4.9382e-01, -2.3080e-02, -8.8175e-03,  1.2468e-14,\n",
      "          1.5580e-16, -2.6537e-16, -6.4694e-17,  7.5602e-18,  1.1836e-18,\n",
      "         -3.2809e-18, -3.0618e-17],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02],\n",
      "        [       -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf,  1.0000e+02]], dtype=torch.float64)\n",
      "logits temp tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0325, 0.0329, 0.0280, 0.0294, 0.0329, 0.0304, 0.0440, 0.0491, 0.0305,\n",
      "         0.0275, 0.0248, 0.0283, 0.0305, 0.0305, 0.0305, 0.0305, 0.0305, 0.0305,\n",
      "         0.0305, 0.0305, 0.0305, 0.0305, 0.0305, 0.0305, 0.0305, 0.0305, 0.0305,\n",
      "         0.0305, 0.0305, 0.0305, 0.0305, 0.0305],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0328, 0.0281, 0.0283, 0.0309, 0.0282, 0.0282, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0463, 0.0399, 0.0366, 0.0417, 0.0295, 0.0298, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000]], dtype=torch.float64)\n",
      "W torch.Size([20, 20])\n",
      "Uncertainty (higher=more uncertain)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%cd UQ-NLG/\n",
    "import sys; sys.path.append(\"..\")\n",
    "from importlib import reload\n",
    "import persist_to_disk as ptd\n",
    "import os\n",
    "ptd.config.set_project_path(os.path.abspath(\"../\"))\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "import re\n",
    "import torch\n",
    "\n",
    "import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "CONTRADICT, NEUTRAL, AGREE = 0, 1, 2\n",
    "# logits: [Contradiction, neutral, entailment]\n",
    "data_path = 'notebook/demo_data.pkl'\n",
    "\n",
    "demo_data = pd.read_pickle(data_path)[:5]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import pipeline.uq_bb as uq_bb\n",
    "reload(uq_bb)\n",
    "obj = uq_bb.UQ_summ(demo_data, clean=True)\n",
    "\n",
    "_u, _c = obj.get_uq('generations|eccentricity|agreement_w', temperature=1.5, eigv_threshold=0.9)\n",
    "print(\"Uncertainty (higher=more uncertain)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8c20de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc                                       0.54410\n",
       "_cnt                                    500.00000\n",
       "generations|eccentricity|agreement_w      0.87392\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequence_dict0 {'exact_match': 0.0, 'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
    "# rouge_results {'rouge1': 1.0, 'rouge2': 0.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
    "\n",
    "num_gens = 20\n",
    "summ_kwargs = {\n",
    "    'u+ea': {'overall': True, 'use_conf': False},\n",
    "    'u+ia': {'overall': False, 'use_conf': False},\n",
    "    'c+ia': {'overall': False, 'use_conf': True},\n",
    "}['c+ia']\n",
    "\n",
    "\n",
    "summ_obj_ = obj.summ(['generations|eccentricity|agreement_w'],\n",
    "\n",
    "    acc_name='generations|rougeL|acc',\n",
    "    num_gens=num_gens, **summ_kwargs\n",
    ")\n",
    "\n",
    "# summ_obj_.summ_overall('auarc')\n",
    "sum(summ_obj_.summ_individual('auroc', use_conf=True)) / num_gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb7ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c555050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 14:40:51.472831: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-04 14:40:52.287800: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing similarities: 100%|█████████████████| 500/500 [01:28<00:00,  5.67it/s]\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/myenv1/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:642: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = self.explained_variance_ / total_var\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/myenv1/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:642: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = self.explained_variance_ / total_var\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/myenv1/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:642: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = self.explained_variance_ / total_var\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/myenv1/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:642: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = self.explained_variance_ / total_var\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/myenv1/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:642: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = self.explained_variance_ / total_var\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/myenv1/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:642: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = self.explained_variance_ / total_var\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "/data/user-data/sa25729/GPT/UQ-NLG/pipeline/uq_bb.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ret[i,j] = torch.tensor(sim_mat[mapping[i], mapping[j]])\n",
      "100%|████████████████████████████████████████| 500/500 [00:01<00:00, 434.67it/s]\n",
      "projecting: 100%|████████████████████████████| 500/500 [00:00<00:00, 708.35it/s]\n",
      "100%|████████████████████████████████████████| 500/500 [00:00<00:00, 688.35it/s]\n",
      "projecting: 100%|████████████████████████████| 500/500 [00:00<00:00, 735.34it/s]\n",
      "100%|███████████████████████████████████████| 500/500 [00:00<00:00, 1832.78it/s]\n",
      "projecting: 100%|███████████████████████████| 500/500 [00:00<00:00, 2492.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "acc                                                0.544100\n",
       "_cnt                                             500.000000\n",
       "generations|numsets                                0.500000\n",
       "lexical_sim                                        0.748345\n",
       "generations|spectral_eigv_clip|disagreement_w      0.816309\n",
       "generations|eccentricity|disagreement_w            0.332705\n",
       "generations|degree|disagreement_w                  0.858068\n",
       "generations|spectral_eigv_clip|agreement_w         0.816449\n",
       "generations|eccentricity|agreement_w               0.875071\n",
       "generations|degree|agreement_w                     0.869696\n",
       "generations|spectral_eigv_clip|jaccard             0.833845\n",
       "generations|eccentricity|jaccard                   0.907041\n",
       "generations|degree|jaccard                         0.934246\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd UQ-NLG/\n",
    "import sys; sys.path.append(\"..\")\n",
    "from importlib import reload\n",
    "import persist_to_disk as ptd\n",
    "import os\n",
    "ptd.config.set_project_path(os.path.abspath(\"../\"))\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "import re\n",
    "import torch\n",
    "\n",
    "import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "CONTRADICT, NEUTRAL, AGREE = 0, 1, 2\n",
    "# logits: [Contradiction, neutral, entailment]\n",
    "data_path = 'demo_data.pkl'\n",
    "\n",
    "demo_data = pd.read_pickle(data_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import pipeline.uq_bb as uq_bb\n",
    "reload(uq_bb)\n",
    "\n",
    "\n",
    "# obj = uq_bb.UQ_summ(path, clean=True, split='test', cal_size=1000, seed=1)\n",
    "obj = uq_bb.UQ_summ(demo_data, clean=True)\n",
    "\n",
    "num_gens = 20\n",
    "summ_kwargs = {\n",
    "    'u+ea': {'overall': True, 'use_conf': False},\n",
    "    'u+ia': {'overall': False, 'use_conf': False},\n",
    "    'c+ia': {'overall': False, 'use_conf': True},\n",
    "}['c+ia']\n",
    "\n",
    "summ_obj = obj.summ([\n",
    "'generations|numsets', 'lexical_sim',\n",
    "    \n",
    "        'generations|spectral_eigv_clip|disagreement_w',\n",
    "        'generations|eccentricity|disagreement_w',\n",
    "        'generations|degree|disagreement_w',\n",
    "\n",
    "        'generations|spectral_eigv_clip|agreement_w',\n",
    "        'generations|eccentricity|agreement_w',\n",
    "        'generations|degree|agreement_w',\n",
    "\n",
    "\n",
    "        'generations|spectral_eigv_clip|jaccard',\n",
    "        'generations|eccentricity|jaccard',\n",
    "        'generations|degree|jaccard',\n",
    "    \n",
    "#         'semanticEntropy|unnorm', 'self_prob',\n",
    "], \n",
    "    \n",
    "    acc_name='generations|rougeL|acc',\n",
    "    num_gens=num_gens, **summ_kwargs\n",
    ")\n",
    "\n",
    "sum(summ_obj.summ_individual('auroc', use_conf=True)) / num_gens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a5199c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6192fc96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c8ac84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandarallel\n",
      "  Downloading pandarallel-1.6.5.tar.gz (14 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: dill>=0.3.1 in /data/user-data/sa25729/myenv1/lib/python3.8/site-packages (from pandarallel) (0.3.6)\n",
      "Requirement already satisfied: pandas>=1 in /data/user-data/sa25729/myenv1/lib/python3.8/site-packages (from pandarallel) (2.0.1)\n",
      "Requirement already satisfied: psutil in /data/user-data/sa25729/myenv1/lib/python3.8/site-packages (from pandarallel) (5.9.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /data/user-data/sa25729/myenv1/lib/python3.8/site-packages (from pandas>=1->pandarallel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /data/user-data/sa25729/myenv1/lib/python3.8/site-packages (from pandas>=1->pandarallel) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /data/user-data/sa25729/myenv1/lib/python3.8/site-packages (from pandas>=1->pandarallel) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /data/user-data/sa25729/myenv1/lib/python3.8/site-packages (from pandas>=1->pandarallel) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /data/user-data/sa25729/myenv1/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas>=1->pandarallel) (1.16.0)\n",
      "Building wheels for collected packages: pandarallel\n",
      "  Building wheel for pandarallel (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandarallel: filename=pandarallel-1.6.5-py3-none-any.whl size=16677 sha256=b34b4737db5b59304a56023e9750e81038f0f72d32a0b8192d45dd04f88bab10\n",
      "  Stored in directory: /data/user-data/sa25729/.cache/pip/wheels/c7/e9/78/48eb140b79de41c4d9440938ef5f9e3186c979183fe57829b3\n",
      "Successfully built pandarallel\n",
      "Installing collected packages: pandarallel\n",
      "Successfully installed pandarallel-1.6.5\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d382c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
